{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA PREPARATION STARTING FROM DATAFRAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pathlib\n",
    "import pickle as pkl\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datestamp = \"20241030-125950\"\n",
    "sim_folder = \"/mnt/c/Users/nikko/OneDrive/Documents/Uni/magistrale/tesi/simulations\"\n",
    "\n",
    "#Directory defining\n",
    "sim_folder = pathlib.Path(sim_folder)\n",
    "datafolder = sim_folder / datestamp / \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_list = []\n",
    "for path in datafolder.iterdir():\n",
    "    if path.is_dir():\n",
    "        num = path.name[3:]\n",
    "        df_path = path / f\"{datestamp}_run{num}.txt\"\n",
    "        path_list.append(df_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "for path in path_list:\n",
    "    df_list.append(pd.read_csv(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestep = 1e-5\n",
    "if len(np.unique(df_list[0].Time)) != max(df_list[0].Time):\n",
    "    timestep = timestep*(max(df_list[0].Time)-1)/(len(np.unique(df_list[0].Time))-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Velocity calc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am dropping the first instant for velocity is obv. NaN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in df_list:\n",
    "    df.sort_values(by=[\"N\",\"Time\"],inplace=True)\n",
    "    df[[\"vx\",\"vy\"]] = df.groupby(\"N\")[[\"xpos\",\"ypos\"]].diff()/timestep #velocity calculation\n",
    "    df.dropna(inplace=True)\n",
    "    df[\"Time\"]=df[\"Time\"]-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_exp = len(df_list)\n",
    "Np = df_list[0].N.max()\n",
    "num_steps = len(np.unique(df_list[0].Time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Position reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppos = []\n",
    "for df in df_list:\n",
    "    Np = df.N.max()\n",
    "    x = np.array(df.xpos).reshape(Np,-1)\n",
    "    y = np.array(df.ypos).reshape(Np,-1)\n",
    "    xy = np.stack([x,y],axis=2)\n",
    "    ppos.append(xy)\n",
    "# position = np.concatenate(ppos,axis=1)\n",
    "position = np.stack(ppos,axis=3)\n",
    "position = np.transpose(position,(3,1,0,2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Velocity reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vv = []\n",
    "for df in df_list:\n",
    "    vx = np.array(df.vx).reshape(Np,-1)\n",
    "    vy = np.array(df.vy).reshape(Np,-1)\n",
    "    vxy = np.stack([vx,vy],axis=2)\n",
    "    vv.append(vxy)\n",
    "vel = np.stack(vv,axis=3)\n",
    "vel = np.transpose(vel,(3,1,0,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "force_ = []\n",
    "for df in df_list:\n",
    "    Np = df.N.max()\n",
    "    fx = np.array(df.fx).reshape(Np,-1)\n",
    "    fy = np.array(df.fy).reshape(Np,-1)\n",
    "    fxy = np.stack([fx,fy],axis=2)\n",
    "    force_.append(fxy)\n",
    "# position = np.concatenate(ppos,axis=1)\n",
    "force = np.stack(force_,axis=3)\n",
    "force = np.transpose(force,(3,1,0,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Orientation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "angle_ = []\n",
    "for df in df_list:\n",
    "    Np = df.N.max()\n",
    "    theta = np.array(df.orientation).reshape(Np,-1)\n",
    "    angle_.append(theta)\n",
    "angle = np.stack(angle_, axis=2)[:,np.newaxis]\n",
    "angle = np.transpose(angle,(3,2,0,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drag Coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = 2.\n",
    "gamma = 6*np.pi*R*1e-3\n",
    "gamma = np.repeat(gamma, Np)\n",
    "gamma = gamma[:,np.newaxis]\n",
    "gamma = np.tile(gamma,(num_exp,num_steps,1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = list(itertools.combinations(range(Np), 2))\n",
    "edges = np.array(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"position\": position,\n",
    "    \"velocity\": vel,\n",
    "    \"drag_coefficient\": gamma,\n",
    "    \"edge_list\": edges,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data.pkl', '+rb') as f:\n",
    "    pkl.dump(data, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "abp_inference",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
